# <img src="Figures/rigbench_logo.png" alt="icon" width="45"/> A Rigorous Benchmark with Multidimensional Evaluation for Deep Research Agents: From Answers to Reports

### arXiv Preprint 2025

**Yang Yao窶ズixu Wang窶ズuxuan Zhang窶ズi Lu窶サianle Gu窶キingyu Li<br>Dingyi Zhao窶ガeming Wu窶ォaozhe Wang窶ケing Nie窶ズan Teng窶ズingchun Wang**<br>
*Shanghai Artificial Intelligence Laboratory窶サhe University of Hong Kong<br>Fudan University窶ザniversity of British Columbia窶ザniversity of Toronto<br>Tsinghua University 窶ゴhanghai Jiao Tong University<br>Hong Kong University of Science and Technology窶ケeking University*


---

## 洫 Abstract

Artificial intelligence is undergoing the paradigm shift from closed language models to interconnected agent systems capable of external perception and information integration. As a representative embodiment, Deep Research Agents (DRAs) systematically exhibit the capabilities for task decomposition, cross-source retrieval, multi-stage reasoning, and structured output, which markedly enhance performance on complex and open-ended tasks. However, existing benchmarks remain deficient in evaluation dimensions, response formatting, and scoring mechanisms, limiting their capacity to assess such systems effectively. This paper introduces a rigorous benchmark and a multidimensional evaluation framework tailored to DRAs and report-style responses. The benchmark comprises 214 expert-curated challenging queries distributed across 10 broad thematic domains, each accompanied by manually constructed reference bundles to support composite evaluation. The framework enables comprehensive evaluation of long-form reports generated by DRAs, incorporating integrated scoring metrics for semantic quality, topical focus, and retrieval trustworthiness. Extensive experimentation confirms the superior performance of mainstream DRAs over web-search-tool-augmented reasoning models, yet reveals considerable scope for further improvement. This study provides a robust foundation for capability assessment, architectural refinement, and paradigm advancement in DRA systems.


## 洫ｪ Installation

```
git clone https://github.com/EVIGBYEN/RigorousBench.git
cd RigorousBench
```

## 沒 Citation

```
@article{yao2025rigorous,
  title={A Rigorous Benchmark with Multidimensional Evaluation for Deep Research Agents: From Answers to Reports},
  author={Yao, Yang and Wang, Yixu and Zhang, Yuxuan and Lu, Yi and Gu, Tianle and Li, Lingyu and Zhao, Dingyi and Wu, Keming and Wang, Haozhe and Nie, Ping and others},
  journal={arXiv preprint arXiv:2510.02190},
  year={2025}
}
```
